from google.colab import drive
drive.mount('/content/drive')

//GETTING STARTED

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from pathlib import Path
import tensorflow as tf

from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils.fixes import sklearn
print(tf.__version__)
print(tf.keras.__version__)
print(np.__version__)
print(pd.__version__)

print(sklearn.__version__)

# Turn the directory paths into Path object
train_dir_pos = Path('/content/drive/MyDrive/Datasets/Projects/Bridge_Cracks_Detection/train/Positive')
train_dir_neg = Path('/content/drive/MyDrive/Datasets/Projects/Bridge_Cracks_Detection/train/Negative')

test_dir_pos = Path('/content/drive/MyDrive/Datasets/Projects/Bridge_Cracks_Detection/test/Positive')
test_dir_neg = Path('/content/drive/MyDrive/Datasets/Projects/Bridge_Cracks_Detection/test/Negative')

valid_dir_pos = Path('/content/drive/MyDrive/Datasets/Projects/Bridge_Cracks_Detection/valid/Positive')
valid_dir_neg = Path('/content/drive/MyDrive/Datasets/Projects/Bridge_Cracks_Detection/valid/Negative')

//CREATING DATAFRAME

def generate_df(image_dir, label):
    """
    Create the DataFrame of the associated directory and label.
    """
    
    filepaths = pd.Series(list(image_dir.glob(r'*.jpg')), name='Filepath').astype(str)
    labels = pd.Series(label, name='Label', index=filepaths.index)
    df = pd.concat([filepaths, labels], axis=1)
    
    return df
# Check Train DataFrame
positive_df_train = generate_df(train_dir_pos, 'POSITIVE')
negative_df_train = generate_df(train_dir_neg, 'NEGATIVE')

# Concatenate DataFrame (on top of each other)
data_train = pd.concat([positive_df, negative_df], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)
data_train.head()

# Check Test DataFrame
positive_df_test = generate_df(test_dir_pos, 'POSITIVE')
negative_df_test = generate_df(test_dir_neg, 'NEGATIVE')


# Concatenate DataFrame (on top of each other)
data_test = pd.concat([positive_df_test, negative_df_test], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)
data_test.head()


# Check Valid DataFrame
positive_df_valid = generate_df(valid_dir_pos, 'POSITIVE')
negative_df_valid = generate_df(valid_dir_neg, 'NEGATIVE')


# Concatenate DataFrame (on top of each other)
data_valid = pd.concat([positive_df_valid, negative_df_valid], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)
data_valid.head()

//LOADING IMAGE DATA

# Image generator for the training set
train_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
)

# Image generator for the test set
test_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255
)
# Generate training images
train_images = train_generator.flow_from_dataframe(
    data_train,
    x_col='Filepath',
    y_col='Label',
    target_size=(120, 120),
    color_mode='rgb',
    class_mode='binary',
    batch_size=32,
    shuffle=True,
    seed=42,
)

# Generate validation images
val_images = test_generator.flow_from_dataframe(
    data_valid,
    x_col='Filepath',
    y_col='Label',
    target_size=(120, 120),
    color_mode='rgb',
    class_mode='binary',
    batch_size=32,
    shuffle=True,
    seed=42,
)

# Generate test images
test_images = test_generator.flow_from_dataframe(
    data_test,
    x_col='Filepath',
    y_col='Label',
    target_size=(120, 120),
    color_mode='rgb',
    class_mode='binary',
    batch_size=32,
    shuffle=False
)
//TRAINING

# Create the layers
inputs = tf.keras.Input(shape=(120, 120, 3))
x = tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu')(inputs)
x = tf.keras.layers.MaxPool2D(pool_size=2)(x)


x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')(x)
x = tf.keras.layers.MaxPool2D(pool_size=2)(x)


x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)


outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)
# Create the model
model = tf.keras.Model(inputs=inputs, outputs=outputs)
model.summary()

# Compile the model
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
# History
history = model.fit(
    train_images,
    validation_data=val_images,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )
    ]
)

fig = px.line(
    history.history,
    y=['loss', 'val_loss'],
    labels={'index': "Epochs", 'value':"Loss"},
    title=("Training and Validation Loss over Time")
)

fig.show()



//RESULTS

y_pred = (model.predict(test_images).squeeze() >= 0.5).astype(int)

def evaluate_model(model):
    
    results = model.evaluate(test_images, verbose=0)
    loss = results[0]
    acc = results[1]
    
    print("Test Loss: {:.5f}".format(loss))
    print("Accuracy: {:.2f}%".format(acc * 100))
    
    cm = confusion_matrix(test_images.labels, y_pred)
    clr = classification_report(test_images.labels, y_pred, target_names=["NEGATIVE", "POSITIVE"])
    
    plt.figure(figsize=(6, 6))
    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)
    plt.xticks(ticks=np.arange(2) + 0.5, labels=["NEGATIVE", "POSITIVE"])
    plt.yticks(ticks=np.arange(2) + 0.5, labels=["NEGATIVE", "POSITIVE"])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()
    
    print("Classification Report:\n------------------------------\n", clr)
    
evaluate_model(model)

    
